{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"bert-base-uncased\", \n",
    "          \"roberta-base\",\n",
    "          \"distilbert-base-uncased\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./20news_bert/\"\n",
    "kmeans_res_path = \"kmeans_res_20News_light_bert.xlsx\"\n",
    "hierarchy_res_path = \"hierarchy_res_20News_light_bert.xlsx\"\n",
    "\n",
    "categories_light = [\"comp.graphics\", \"rec.autos\", \"sci.med\",  \"talk.politics.mideast\"]\n",
    "categories_hard = [\"talk.politics.guns\", \"talk.politics.mideast\",  \"talk.politics.misc\"]\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset=\"train\",\n",
    "                                remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "                                categories=categories_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    tokens = [word.lower() for word in tokens if word.isalnum()]\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words ]\n",
    "    \n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text_by_pos(text, pos_to_keep):\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    \n",
    "    filtered_tokens = [token for token, pos in tagged_tokens if pos in pos_to_keep]\n",
    "    \n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmeans(matrix, metrics, true_labels, num_clusters=2, num_iterations=50):\n",
    "    scores = {}\n",
    "    for metric in metrics:\n",
    "        scores.update({metric.__name__: []})\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        clusters = KMeans(n_clusters=num_clusters, random_state=i, n_init=10)\n",
    "\n",
    "        clusters.fit_predict(matrix)\n",
    "        \n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, clusters.labels_)\n",
    "            scores[metric.__name__].append(score)\n",
    "\n",
    "    kmeans_res = \"\"\n",
    "    for metric in scores:\n",
    "        kmeans_res += f\"\\n{metric} \\nMax: {np.max(scores[metric])} \\\n",
    "                                    \\nMin: {np.min(scores[metric])} \\\n",
    "                                    \\nAVG: {np.mean(scores[metric])} \\n\"\n",
    "        \n",
    "    print(kmeans_res)\n",
    "    return kmeans_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_hierarchy(matrix, metrics, true_labels, num_clusters=2):\n",
    "    linkages = [\"complete\", \"average\", \"single\"]\n",
    "\n",
    "    hierarchy_res = \"\"\n",
    "\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        affinity = \"euclidean\"\n",
    "        matrix = matrix.toarray()\n",
    "        linkages.append(\"ward\")\n",
    "    else:\n",
    "        affinity = \"precomputed\"\n",
    "\n",
    "    for linkage in linkages:\n",
    "        hierarchy_res += f\"\\n{linkage}\"\n",
    "\n",
    "        agg_clustering = AgglomerativeClustering(n_clusters=num_clusters, metric=affinity, linkage=linkage)\n",
    "\n",
    "        agg_clustering.fit_predict(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, agg_clustering.labels_)\n",
    "            hierarchy_res += f\"\\n{metric.__name__}: {score}\"\n",
    "        \n",
    "        hierarchy_res += \"\\n\"\n",
    "    \n",
    "    print(hierarchy_res)\n",
    "    return hierarchy_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset, model_name):\n",
    "    true_labels = dataset.target\n",
    "    distances = [\"none\", \"euclidean\", \"cosine\"]\n",
    "    metrics = [normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score]\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    kmeans_data = pd.DataFrame(columns=distances)\n",
    "    hierarchy_data = pd.DataFrame(columns=distances)\n",
    "\n",
    "    preprocessed_data = [preprocess_text(text) for text in dataset.data]\n",
    "\n",
    "    noun_data = [filter_text_by_pos(text, pos_to_keep=['NN', 'NNS']) for text in preprocessed_data]\n",
    "    adj_data = [filter_text_by_pos(text, pos_to_keep=['JJ', 'JJR', 'JJS']) for text in preprocessed_data]\n",
    "    noun_adj_data = [filter_text_by_pos(text, pos_to_keep=['NN', 'NNS', 'JJ', 'JJR', 'JJS']) for text in preprocessed_data]\n",
    "\n",
    "    list_of_data = {\"ALL\": preprocessed_data, \"NOUNS\": noun_data, \"ADJ\": adj_data, \"NOUNS and ADJ\": noun_adj_data}\n",
    "\n",
    "    for name, data in list_of_data.items():\n",
    "        tokens = tokenizer(data, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(**tokens).last_hidden_state\n",
    "        \n",
    "        for distance in distances:\n",
    "            if distance == \"euclidean\":\n",
    "                distance_matrix = euclidean_distances(embeddings)\n",
    "            elif distance == \"cosine\":\n",
    "                distance_matrix = 1 - cosine_distances(embeddings)\n",
    "            elif distance == \"none\":\n",
    "                distance_matrix = embeddings\n",
    "\n",
    "            kmeans_data.loc[name, distance] = cluster_kmeans(distance_matrix, metrics, true_labels, num_clusters=len(dataset.target_names))\n",
    "\n",
    "            hierarchy_data.loc[name, distance] = cluster_hierarchy(distance_matrix, metrics, true_labels, num_clusters=len(dataset.target_names))\n",
    "\n",
    "    return kmeans_data, hierarchy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3674210304 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\20news_cluster_bert.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Andrey/%D0%BF%D1%80%D0%BE%D0%B3%D0%B0/python/document_classification/20news_cluster_bert.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m model_name \u001b[39min\u001b[39;00m models:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Andrey/%D0%BF%D1%80%D0%BE%D0%B3%D0%B0/python/document_classification/20news_cluster_bert.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(model_name)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Andrey/%D0%BF%D1%80%D0%BE%D0%B3%D0%B0/python/document_classification/20news_cluster_bert.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     kmeans_data, hierarchy_data \u001b[39m=\u001b[39m main(newsgroups, model_name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Andrey/%D0%BF%D1%80%D0%BE%D0%B3%D0%B0/python/document_classification/20news_cluster_bert.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     kmeans_data\u001b[39m.\u001b[39mto_excel(folder \u001b[39m+\u001b[39m model_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m kmeans_res_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Andrey/%D0%BF%D1%80%D0%BE%D0%B3%D0%B0/python/document_classification/20news_cluster_bert.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     hierarchy_data\u001b[39m.\u001b[39mto_excel(folder \u001b[39m+\u001b[39m model_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m hierarchy_res_path)\n",
      "\u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\20news_cluster_bert.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Andrey/%D0%BF%D1%80%D0%BE%D0%B3%D0%B0/python/document_classification/20news_cluster_bert.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m tokens \u001b[39m=\u001b[39m tokenizer(data, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Andrey/%D0%BF%D1%80%D0%BE%D0%B3%D0%B0/python/document_classification/20news_cluster_bert.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Andrey/%D0%BF%D1%80%D0%BE%D0%B3%D0%B0/python/document_classification/20news_cluster_bert.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     embeddings \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtokens)\u001b[39m.\u001b[39mlast_hidden_state\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Andrey/%D0%BF%D1%80%D0%BE%D0%B3%D0%B0/python/document_classification/20news_cluster_bert.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m distance \u001b[39min\u001b[39;00m distances:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Andrey/%D0%BF%D1%80%D0%BE%D0%B3%D0%B0/python/document_classification/20news_cluster_bert.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mif\u001b[39;00m distance \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1015\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[0;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1018\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1019\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[0;32m   1023\u001b[0m     embedding_output,\n\u001b[0;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m   1033\u001b[0m )\n\u001b[0;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:232\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    229\u001b[0m         token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_ids\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_embeddings(input_ids)\n\u001b[0;32m    233\u001b[0m token_type_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m    235\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m token_type_embeddings\n",
      "File \u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32md:\\Andrey\\прога\\python\\document_classification\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2227\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2233\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3674210304 bytes."
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    kmeans_data, hierarchy_data = main(newsgroups, model_name)\n",
    "    \n",
    "    kmeans_data.to_excel(folder + model_name + \"/\" + kmeans_res_path)\n",
    "    hierarchy_data.to_excel(folder + model_name + \"/\" + hierarchy_res_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
